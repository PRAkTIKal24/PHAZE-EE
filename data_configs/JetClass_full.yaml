treename: tree

selection:
   ### use `&` for logical AND, `|` for logical OR
   ### can use functions from `math`, `np` (numpy), and `awkward` in the expression
   (jet_pt > 500) & (jet_pt < 1000) & (abs(jet_eta) < 2)

test_time_selection:
   (jet_pt > 500) & (jet_pt < 1000) & (abs(jet_eta) < 2)

new_variables:
   ### [format] name: formula
   ### MUST use vectorized operations (e.g., np.where, np.sqrt, etc.)
   ### can use functions from `math`, `np` (numpy), and `awkward` in the expression
   part_mask: ak.ones_like(part_energy)
   part_pt: np.hypot(part_px, part_py)
   part_pt_log: np.log(part_pt)
   part_e_log: np.log(part_energy)
   part_logptrel: np.log(part_pt/jet_pt)
   part_logerel: np.log(part_energy/jet_energy)
   part_deltaR: np.hypot(part_deta, part_dphi)
   part_d0val_abs: np.abs(part_d0val)
   part_d0err_log: np.log(part_d0err)
   part_dzval_abs: np.abs(part_dzval)
   part_dzerr_log: np.log(part_dzerr)

preprocess:
  ### method: [manual, auto] - whether to use manually specified parameters for variable standardization
  method: manual
  ### data_fraction: fraction of events to use when calculating the mean/scale for the standardization
  data_fraction: 0.1

inputs:
   pf_points:
      length: 128
      vars:
         ### [format 1]: var_name (no transformation)
         ### [format 2]: [var_name, 
         ###              subtract_by(optional, default=None, no transf. if preprocess.method=manual, auto transf. if preprocess.method=auto), 
         ###              multiply_by(optional, default=1), 
         ###              clip_min(optional, default=-5), 
         ###              clip_max(optional, default=5), 
         ###              pad_value(optional, default=0)]
         - [part_deta, null]
         - [part_dphi, null]
   pf_features:
      length: 128
      vars:
      ### default: [var_name, standardization, clip_min=-5, clip_max=5, pad_value=0]
         - [part_pt_log, 1.7, 0.7]
         - [part_e_log, 2.0, 0.7]
         - [part_logptrel, -4.7, 0.7]
         - [part_logerel, -4.7, 0.7]
         - [part_deltaR, 0.2, 0.2]
         - [part_d0val, null]
         - [part_d0val_abs, 0.0, 0.3]
         - [part_d0err, null]
         - [part_d0err_log, -3.3, 1.2]
         - [part_dzval, null]
         - [part_dzval_abs, 0.0, 3.0]
         - [part_dzerr, null]
         - [part_dzerr_log, -2.0, 1.2]
         - [part_charge, null]
         - [part_isChargedHadron, null]
         - [part_isNeutralHadron, null]
         - [part_isPhoton, null]
         - [part_isElectron, null]
         - [part_isMuon, null]
   pf_vectors:
      length: 128
      vars:
         - [part_px, null]
         - [part_py, null]
         - [part_pz, null]
         - [part_energy, null]
   pf_mask:
      length: 128
      vars:
         - [part_mask, null]

labels:
   ### type can be `simple`, `custom`
   ### [option 1] use `simple` for binary/multi-class classification, all elements in the `value` list will be used as labels
   ### [option 2] otherwise use `custom` to define the label, then `value` will be a map
   type: simple
   value: 
      - label_QCD
      - label_Hbb
      - label_Hcc
      - label_Hgg
      - label_H4q
      - label_Hqql
      - label_Zqq
      - label_Wqq
      - label_Tbqq
      - label_Tbl

observers:
   - jet_pt
   - jet_eta
   - jet_phi
   - jet_energy
   - jet_nparticles
   - jet_sdmass

weights:
   ### [option 1] use precomputed weights stored in the input files
   # use_precomputed_weights: true
   # weight_branches: [weight, class_weight]
   ### [option 2] class reweighting: use 'class_weights' to perform class-balancing
   # class_weights:
   #   - [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  # values for [QCD, Hbb, Hcc, Hgg, H4q, Hqql, Zqq, Wqq, Tbqq, Tbl]
   ### [option 3] no weights
   use_precomputed_weights: false
